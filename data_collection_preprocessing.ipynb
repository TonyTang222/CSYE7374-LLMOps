{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1uxQ7NHMk5-kW6b72cjaTuzi0_xKcpfoD",
     "timestamp": 1769279342153
    }
   ],
   "authorship_tag": "ABX9TyMrrJgkeDvmXqxnQk0iLGL3"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "110348d73ecf4bc8aca02e8e9ad6aeb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "HBoxModel",
      "model_module_version": "1.5.0",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bcdfb1c950284d36b0ec5ca175fd0a79",
        "IPY_MODEL_ad4e0005a7b440f9bee549f5150fde47",
        "IPY_MODEL_2ff517d054374892a9fcb5b0601ca681"
       ],
       "layout": "IPY_MODEL_ac8e6c7fab0641b9b920bfe641084c8d"
      }
     },
     "bcdfb1c950284d36b0ec5ca175fd0a79": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "HTMLModel",
      "model_module_version": "1.5.0",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d22ce8b2243644438da2c9fda1e50d5e",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_f1dc62a5f3aa401ea964b1d90f5f1c57",
       "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
      }
     },
     "ad4e0005a7b440f9bee549f5150fde47": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "FloatProgressModel",
      "model_module_version": "1.5.0",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0ef5912f7bdf4a8b977628bef00a1e8f",
       "max": 41,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_029ac290ad274342b5115ec21dcdc497",
       "value": 41
      }
     },
     "2ff517d054374892a9fcb5b0601ca681": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "HTMLModel",
      "model_module_version": "1.5.0",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_66072f43151f4d8f8dd8cad4303486af",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_b4301d5afa7e44b4b9e73965e15e995a",
       "value": "â€‡41/41â€‡[00:00&lt;00:00,â€‡â€‡3.20it/s]"
      }
     },
     "ac8e6c7fab0641b9b920bfe641084c8d": {
      "model_module": "@jupyter-widgets/base",
      "model_name": "LayoutModel",
      "model_module_version": "1.2.0",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d22ce8b2243644438da2c9fda1e50d5e": {
      "model_module": "@jupyter-widgets/base",
      "model_name": "LayoutModel",
      "model_module_version": "1.2.0",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f1dc62a5f3aa401ea964b1d90f5f1c57": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "DescriptionStyleModel",
      "model_module_version": "1.5.0",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0ef5912f7bdf4a8b977628bef00a1e8f": {
      "model_module": "@jupyter-widgets/base",
      "model_name": "LayoutModel",
      "model_module_version": "1.2.0",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "029ac290ad274342b5115ec21dcdc497": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "ProgressStyleModel",
      "model_module_version": "1.5.0",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "66072f43151f4d8f8dd8cad4303486af": {
      "model_module": "@jupyter-widgets/base",
      "model_name": "LayoutModel",
      "model_module_version": "1.2.0",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b4301d5afa7e44b4b9e73965e15e995a": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "DescriptionStyleModel",
      "model_module_version": "1.5.0",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "74bdfedb725140cfbdd1cbafb31423a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "HBoxModel",
      "model_module_version": "1.5.0",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_32ea5e067d1241c39a996c1a93ee1122",
        "IPY_MODEL_904e6d35554843e4a8224a8c81d50f7c",
        "IPY_MODEL_9ec4bc1996a548afa3f86a433d7c7b85"
       ],
       "layout": "IPY_MODEL_bf15babd6312458996b6e58162cece77"
      }
     },
     "32ea5e067d1241c39a996c1a93ee1122": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "HTMLModel",
      "model_module_version": "1.5.0",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_52bb2ee52dc843f685b2b5ab875a979f",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_085f47505bc04857a0ac2da15921dc9e",
       "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
      }
     },
     "904e6d35554843e4a8224a8c81d50f7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "FloatProgressModel",
      "model_module_version": "1.5.0",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3e6616e7eecf42e6a7c5707fb44212e2",
       "max": 80,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_42a1ac49078c4129b6aeef4dedf1b9c7",
       "value": 80
      }
     },
     "9ec4bc1996a548afa3f86a433d7c7b85": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "HTMLModel",
      "model_module_version": "1.5.0",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5d7ccf9e648443ce958b11b2e824ebd7",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_26f6966e1e34489ebadff91fe32bc68e",
       "value": "â€‡80/80â€‡[00:00&lt;00:00,â€‡12.40it/s]"
      }
     },
     "bf15babd6312458996b6e58162cece77": {
      "model_module": "@jupyter-widgets/base",
      "model_name": "LayoutModel",
      "model_module_version": "1.2.0",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "52bb2ee52dc843f685b2b5ab875a979f": {
      "model_module": "@jupyter-widgets/base",
      "model_name": "LayoutModel",
      "model_module_version": "1.2.0",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "085f47505bc04857a0ac2da15921dc9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "DescriptionStyleModel",
      "model_module_version": "1.5.0",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3e6616e7eecf42e6a7c5707fb44212e2": {
      "model_module": "@jupyter-widgets/base",
      "model_name": "LayoutModel",
      "model_module_version": "1.2.0",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "42a1ac49078c4129b6aeef4dedf1b9c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "ProgressStyleModel",
      "model_module_version": "1.5.0",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5d7ccf9e648443ce958b11b2e824ebd7": {
      "model_module": "@jupyter-widgets/base",
      "model_name": "LayoutModel",
      "model_module_version": "1.2.0",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "26f6966e1e34489ebadff91fe32bc68e": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "DescriptionStyleModel",
      "model_module_version": "1.5.0",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "49355c10a05447e6a6f1484b7624ccb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "HBoxModel",
      "model_module_version": "1.5.0",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1dfa62ed48b5428791441427545d3634",
        "IPY_MODEL_873012c1265a483096c2972e7d810408",
        "IPY_MODEL_d52182e8e9964fcdbba53456b7436bb0"
       ],
       "layout": "IPY_MODEL_b6d2c94dcd294dac9ce6e7b3a868fee7"
      }
     },
     "1dfa62ed48b5428791441427545d3634": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "HTMLModel",
      "model_module_version": "1.5.0",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_249ee4f556174708970279010aca3221",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_18a781d000854985b7c8afcb684427f7",
       "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
      }
     },
     "873012c1265a483096c2972e7d810408": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "FloatProgressModel",
      "model_module_version": "1.5.0",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e9f1c6ed2f71428395377ffd6b60e251",
       "max": 80,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_903505210ee44634bed282c23a8d1781",
       "value": 80
      }
     },
     "d52182e8e9964fcdbba53456b7436bb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "HTMLModel",
      "model_module_version": "1.5.0",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2f900b95c86a48828b45ece489471f6f",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_2e614251b8fe4838819eb1d6da7b4b54",
       "value": "â€‡80/80â€‡[00:00&lt;00:00,â€‡4217.18it/s]"
      }
     },
     "b6d2c94dcd294dac9ce6e7b3a868fee7": {
      "model_module": "@jupyter-widgets/base",
      "model_name": "LayoutModel",
      "model_module_version": "1.2.0",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "249ee4f556174708970279010aca3221": {
      "model_module": "@jupyter-widgets/base",
      "model_name": "LayoutModel",
      "model_module_version": "1.2.0",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18a781d000854985b7c8afcb684427f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "DescriptionStyleModel",
      "model_module_version": "1.5.0",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e9f1c6ed2f71428395377ffd6b60e251": {
      "model_module": "@jupyter-widgets/base",
      "model_name": "LayoutModel",
      "model_module_version": "1.2.0",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "903505210ee44634bed282c23a8d1781": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "ProgressStyleModel",
      "model_module_version": "1.5.0",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2f900b95c86a48828b45ece489471f6f": {
      "model_module": "@jupyter-widgets/base",
      "model_name": "LayoutModel",
      "model_module_version": "1.2.0",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e614251b8fe4838819eb1d6da7b4b54": {
      "model_module": "@jupyter-widgets/controls",
      "model_name": "DescriptionStyleModel",
      "model_module_version": "1.5.0",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hQmqzOQq3il"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assignment 1: Data Collection and Preprocessing for Foundation Model Pre-Training\n",
    "Complete implementation with dataset collection, cleaning, tokenization, and custom data loader\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Iterator\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# 1. DATA COLLECTION\n",
    "# ============================================================================\n",
    "class DataCollector:\n",
    "    \"\"\"Handles collection of diverse text datasets from multiple sources\"\"\"\n",
    "\n",
    "    def __init__(self, output_dir: str = \"./raw_data\"):\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    def collect_wikipedia(self, num_samples: int = 100000):\n",
    "        \"\"\"\n",
    "        Collect Wikipedia articles\n",
    "        Source: English Wikipedia dump\n",
    "        Domain: Encyclopedic knowledge\n",
    "        \"\"\"\n",
    "        print(\"Collecting Wikipedia data...\")\n",
    "        dataset = load_dataset(\"wikimedia/wikipedia\", \"20231101.en\", split=\"train\", streaming=True)\n",
    "\n",
    "        texts = []\n",
    "        for i, example in enumerate(tqdm(dataset, total=num_samples, desc=\"Wikipedia\")):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "            texts.append(example['text'])\n",
    "\n",
    "        output_path = os.path.join(self.output_dir, \"wikipedia.txt\")\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n\\n'.join(texts))\n",
    "\n",
    "        return texts\n",
    "\n",
    "    def collect_openwebtext(self, num_samples: int = 50000):\n",
    "        \"\"\"\n",
    "        Collect OpenWebText data\n",
    "        Source: Reddit links dataset\n",
    "        Domain: General web text, discussions\n",
    "        \"\"\"\n",
    "        print(\"Collecting OpenWebText data...\")\n",
    "        dataset = load_dataset(\"openwebtext\", split=\"train\", streaming=True)\n",
    "\n",
    "        texts = []\n",
    "        for i, example in enumerate(tqdm(dataset, total=num_samples, desc=\"OpenWebText\")):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "            texts.append(example['text'])\n",
    "\n",
    "        output_path = os.path.join(self.output_dir, \"openwebtext.txt\")\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write('\\n\\n'.join(texts))\n",
    "\n",
    "        return texts\n",
    "\n",
    "    def get_dataset_stats(self):\n",
    "        \"\"\"Calculate and display dataset statistics\"\"\"\n",
    "        total_size = 0\n",
    "        stats = {}\n",
    "\n",
    "        for filename in os.listdir(self.output_dir):\n",
    "            filepath = os.path.join(self.output_dir, filename)\n",
    "            size = os.path.getsize(filepath)\n",
    "            total_size += size\n",
    "            stats[filename] = {\n",
    "                'size_mb': size / (1024 * 1024),\n",
    "                'size_gb': size / (1024 * 1024 * 1024)\n",
    "            }\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"DATASET STATISTICS\")\n",
    "        print(\"=\"*60)\n",
    "        for filename, stat in stats.items():\n",
    "            print(f\"{filename}: {stat['size_mb']:.2f} MB ({stat['size_gb']:.4f} GB)\")\n",
    "        print(f\"\\nTotal Size: {total_size / (1024**3):.4f} GB\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "        return stats"
   ],
   "metadata": {
    "id": "Ar3WxxCmsM1I"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# 2. DATA CLEANING AND PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "class TextCleaner:\n",
    "    \"\"\"Comprehensive text cleaning and normalization\"\"\"\n",
    "\n",
    "    def __init__(self, min_words: int = 50):\n",
    "        self.min_words = min_words\n",
    "        self.seen_hashes = set()\n",
    "\n",
    "    def clean_text(self, text: str) -> str:\n",
    "        \"\"\"Apply all cleaning operations to text\"\"\"\n",
    "        # Remove HTML tags\n",
    "        text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "        # Remove markdown artifacts\n",
    "        text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)  # Remove links\n",
    "        text = re.sub(r'[#*_~`]', '', text)  # Remove markdown symbols\n",
    "\n",
    "        # Remove reference markers like [1], [citation needed]\n",
    "        text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "        text = re.sub(r'\\[citation needed\\]', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "        # Normalize whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = text.strip()\n",
    "\n",
    "        # Remove special characters but keep punctuation\n",
    "        text = re.sub(r'[^\\w\\s.,!?;:\\'\\\"-]', '', text)\n",
    "\n",
    "        return text\n",
    "\n",
    "    def is_low_quality(self, text: str) -> bool:\n",
    "        \"\"\"Check if text is low quality and should be filtered\"\"\"\n",
    "        # Too short\n",
    "        word_count = len(text.split())\n",
    "        if word_count < self.min_words:\n",
    "            return True\n",
    "\n",
    "        # Too many non-alphabetic characters (spam indicators)\n",
    "        alpha_ratio = sum(c.isalpha() or c.isspace() for c in text) / max(len(text), 1)\n",
    "        if alpha_ratio < 0.7:\n",
    "            return True\n",
    "\n",
    "        # Too repetitive (same word repeated many times)\n",
    "        words = text.lower().split()\n",
    "        if len(words) > 0:\n",
    "            most_common_ratio = Counter(words).most_common(1)[0][1] / len(words)\n",
    "            if most_common_ratio > 0.3:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def get_hash(self, text: str) -> str:\n",
    "        \"\"\"Generate hash for deduplication\"\"\"\n",
    "        return hashlib.md5(text.encode('utf-8')).hexdigest()\n",
    "\n",
    "    def is_duplicate(self, text: str) -> bool:\n",
    "        \"\"\"Check if text is duplicate using hash\"\"\"\n",
    "        text_hash = self.get_hash(text)\n",
    "        if text_hash in self.seen_hashes:\n",
    "            return True\n",
    "        self.seen_hashes.add(text_hash)\n",
    "        return False\n",
    "\n",
    "    def process_documents(self, texts: List[str]) -> List[str]:\n",
    "        \"\"\"Process multiple documents with cleaning and filtering\"\"\"\n",
    "        cleaned_texts = []\n",
    "        stats = {\n",
    "            'total': len(texts),\n",
    "            'duplicates': 0,\n",
    "            'low_quality': 0,\n",
    "            'kept': 0\n",
    "        }\n",
    "\n",
    "        for text in tqdm(texts, desc=\"Cleaning documents\"):\n",
    "            # Clean text\n",
    "            cleaned = self.clean_text(text)\n",
    "\n",
    "            # Check for duplicates\n",
    "            if self.is_duplicate(cleaned):\n",
    "                stats['duplicates'] += 1\n",
    "                continue\n",
    "\n",
    "            # Check quality\n",
    "            if self.is_low_quality(cleaned):\n",
    "                stats['low_quality'] += 1\n",
    "                continue\n",
    "\n",
    "            cleaned_texts.append(cleaned)\n",
    "            stats['kept'] += 1\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"CLEANING STATISTICS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Total documents: {stats['total']}\")\n",
    "        print(f\"Duplicates removed: {stats['duplicates']}\")\n",
    "        print(f\"Low quality removed: {stats['low_quality']}\")\n",
    "        print(f\"Documents kept: {stats['kept']}\")\n",
    "        print(f\"Retention rate: {stats['kept']/stats['total']*100:.2f}%\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "        return cleaned_texts"
   ],
   "metadata": {
    "id": "rD2hfl3F-p5D"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# 3. TOKENIZATION\n",
    "# ============================================================================\n",
    "\n",
    "class TextTokenizer:\n",
    "    \"\"\"Handle tokenization with chunking - MEMORY SAFE VERSION\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"gpt2\", max_length: int = 512):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # Add padding token if not present\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        print(f\"\\nTokenizer Info:\")\n",
    "        print(f\"  Model: {model_name}\")\n",
    "        print(f\"  Vocab size: {self.tokenizer.vocab_size}\")\n",
    "        print(f\"  Max length: {max_length}\")\n",
    "        print(f\"  Fast tokenizer: {self.tokenizer.is_fast}\")\n",
    "        print(f\"  Tokenization type: BPE (Byte-Pair Encoding)\\n\")\n",
    "\n",
    "    def tokenize_and_chunk(self, text: str) -> List[List[int]]:\n",
    "        \"\"\"\n",
    "        Tokenize text and chunk into sequences of max_length\n",
    "        Returns list of token sequences\n",
    "        \"\"\"\n",
    "        # Tokenize entire text\n",
    "        tokens = self.tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "        # Chunk into sequences of max_length\n",
    "        chunks = []\n",
    "        for i in range(0, len(tokens), self.max_length):\n",
    "            chunk = tokens[i:i + self.max_length]\n",
    "            if len(chunk) >= 50:  # Only keep chunks with at least 50 tokens\n",
    "                chunks.append(chunk)\n",
    "\n",
    "        return chunks\n",
    "\n",
    "    def process_documents_segments(self,\n",
    "                                   documents: List[str],\n",
    "                                   segment_size: int = 50000,\n",
    "                                   output_dir: str = \"./tokenization_segments\") -> str:\n",
    "        \"\"\"\n",
    "        Process documents in segments to avoid memory issues\n",
    "        Each segment is saved immediately to disk\n",
    "\n",
    "        Returns: output_dir path\n",
    "        \"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        num_segments = (len(documents) + segment_size - 1) // segment_size\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"MEMORY-SAFE SEGMENTED TOKENIZATION\")\n",
    "        print('='*60)\n",
    "        print(f\"  Total documents: {len(documents):,}\")\n",
    "        print(f\"  Segment size: {segment_size:,}\")\n",
    "        print(f\"  Number of segments: {num_segments}\")\n",
    "        print(f\"  Output directory: {output_dir}\")\n",
    "        print('='*60 + '\\n')\n",
    "\n",
    "        total_sequences = 0\n",
    "        batch_size = 5000  # Larger batch size for efficiency\n",
    "\n",
    "        for seg_idx in range(num_segments):\n",
    "            start = seg_idx * segment_size\n",
    "            end = min(start + segment_size, len(documents))\n",
    "            segment_docs = documents[start:end]\n",
    "\n",
    "            segment_file = os.path.join(output_dir, f\"segment_{seg_idx:03d}.pt\")\n",
    "\n",
    "            # Check if already processed\n",
    "            if os.path.exists(segment_file):\n",
    "                print(f\"âœ“ Segment {seg_idx}/{num_segments-1} already exists, loading...\")\n",
    "                segment_data = torch.load(segment_file)\n",
    "                total_sequences += len(segment_data)\n",
    "                del segment_data\n",
    "                continue\n",
    "\n",
    "            print(f\"\\n{'â”€'*60}\")\n",
    "            print(f\"SEGMENT {seg_idx}/{num_segments-1}\")\n",
    "            print(f\"Documents: {start:,} to {end:,}\")\n",
    "            print('â”€'*60)\n",
    "\n",
    "            segment_sequences = []\n",
    "\n",
    "            # Filter short documents\n",
    "            valid_docs = [doc for doc in segment_docs if len(doc.strip()) >= 100]\n",
    "            print(f\"  Valid documents: {len(valid_docs):,}\")\n",
    "\n",
    "            # Process in batches\n",
    "            for i in tqdm(range(0, len(valid_docs), batch_size),\n",
    "                     desc=f\"  Processing\",\n",
    "                     leave=False):\n",
    "              batch_docs = valid_docs[i:i + batch_size]\n",
    "\n",
    "              try:\n",
    "                  # batch tokenize\n",
    "                  encoded = self.tokenizer(\n",
    "                      batch_docs,\n",
    "                      add_special_tokens=False,\n",
    "                      truncation=False,\n",
    "                      return_attention_mask=False,\n",
    "                      padding=False\n",
    "                  )\n",
    "\n",
    "                  # Chunking\n",
    "                  for token_ids in encoded['input_ids']:\n",
    "                      if len(token_ids) > 50000:\n",
    "                          continue\n",
    "\n",
    "                      for j in range(0, len(token_ids), self.max_length):\n",
    "                          chunk = token_ids[j:j + self.max_length]\n",
    "                          if len(chunk) >= 50:\n",
    "                              segment_sequences.append(chunk)\n",
    "\n",
    "                  # âœ… cleaning\n",
    "                  del encoded\n",
    "                  del batch_docs\n",
    "\n",
    "              except Exception as e:\n",
    "                  print(f\"\\n    âš ï¸ Batch {i//batch_size} failed: {str(e)[:100]}\")\n",
    "                  continue\n",
    "\n",
    "              # Clear memory periodically\n",
    "              if i % (batch_size * 3) == 0 and i > 0:\n",
    "                  gc.collect()\n",
    "\n",
    "            # Save this segment immediately\n",
    "            torch.save(segment_sequences, segment_file)\n",
    "            total_sequences += len(segment_sequences)\n",
    "\n",
    "            print(f\"  âœ… Segment complete: {len(segment_sequences):,} sequences\")\n",
    "            print(f\"  ðŸ’¾ Saved to: {segment_file}\")\n",
    "            print(f\"  ðŸ“Š Running total: {total_sequences:,} sequences\")\n",
    "\n",
    "            # Clear memory\n",
    "            del segment_docs\n",
    "            del valid_docs\n",
    "            del segment_sequences\n",
    "            gc.collect()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"âœ… ALL SEGMENTS COMPLETE\")\n",
    "        print('='*60)\n",
    "        print(f\"  Total sequences: {total_sequences:,}\")\n",
    "        print(f\"  Segments saved in: {output_dir}\")\n",
    "        print('='*60 + '\\n')\n",
    "\n",
    "        return output_dir\n",
    "\n",
    "    def load_segments_metadata(self, segment_dir: str) -> dict:\n",
    "        \"\"\"Load metadata about all segments\"\"\"\n",
    "        segment_files = sorted([f for f in os.listdir(segment_dir) if f.endswith('.pt')])\n",
    "\n",
    "        total_sequences = 0\n",
    "        segment_info = []\n",
    "\n",
    "        print(\"Loading segment metadata...\")\n",
    "        for seg_file in segment_files:\n",
    "            seg_path = os.path.join(segment_dir, seg_file)\n",
    "            seg_data = torch.load(seg_path)\n",
    "            count = len(seg_data)\n",
    "            total_sequences += count\n",
    "            segment_info.append({\n",
    "                'file': seg_file,\n",
    "                'count': count\n",
    "            })\n",
    "            del seg_data\n",
    "\n",
    "        return {\n",
    "            'total_sequences': total_sequences,\n",
    "            'num_segments': len(segment_files),\n",
    "            'segments': segment_info\n",
    "        }\n"
   ],
   "metadata": {
    "id": "SWmHu935haY1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# 4. CUSTOM DATASET AND DATALOADER\n",
    "# ============================================================================\n",
    "\n",
    "class SegmentedPretrainingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset that loads segments on-demand\n",
    "    Prevents loading all sequences into memory at once\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, segment_dir: str, max_length: int = 512, pad_token_id: int = 0):\n",
    "        self.segment_dir = segment_dir\n",
    "        self.max_length = max_length\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "        # Find all segment files\n",
    "        self.segment_files = sorted([\n",
    "            f for f in os.listdir(segment_dir) if f.endswith('.pt')\n",
    "        ])\n",
    "\n",
    "        if not self.segment_files:\n",
    "            raise ValueError(f\"No segment files found in {segment_dir}\")\n",
    "\n",
    "        # Count sequences in each segment\n",
    "        print(\"Counting sequences in segments...\")\n",
    "        self.sequence_counts = []\n",
    "        total = 0\n",
    "\n",
    "        for seg_file in tqdm(self.segment_files, desc=\"Loading metadata\"):\n",
    "            seg_path = os.path.join(segment_dir, seg_file)\n",
    "            seg_data = torch.load(seg_path)\n",
    "            count = len(seg_data)\n",
    "            self.sequence_counts.append(count)\n",
    "            total += count\n",
    "            del seg_data\n",
    "\n",
    "        self.total_sequences = total\n",
    "        print(f\"âœ… Total sequences: {self.total_sequences:,}\\n\")\n",
    "\n",
    "        # Currently loaded segment\n",
    "        self.current_segment_idx = None\n",
    "        self.current_segment_data = None\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.total_sequences\n",
    "\n",
    "    def _load_segment(self, segment_idx: int):\n",
    "        \"\"\"Load a specific segment into memory\"\"\"\n",
    "        if self.current_segment_idx != segment_idx:\n",
    "            # Clear old segment\n",
    "            if self.current_segment_data is not None:\n",
    "                del self.current_segment_data\n",
    "                gc.collect()\n",
    "\n",
    "            # Load new segment\n",
    "            seg_file = self.segment_files[segment_idx]\n",
    "            seg_path = os.path.join(self.segment_dir, seg_file)\n",
    "            self.current_segment_data = torch.load(seg_path)\n",
    "            self.current_segment_idx = segment_idx\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        # Find which segment contains this index\n",
    "        cumsum = 0\n",
    "        segment_idx = 0\n",
    "        local_idx = idx\n",
    "\n",
    "        for i, count in enumerate(self.sequence_counts):\n",
    "            if idx < cumsum + count:\n",
    "                segment_idx = i\n",
    "                local_idx = idx - cumsum\n",
    "                break\n",
    "            cumsum += count\n",
    "\n",
    "        # Load the appropriate segment\n",
    "        self._load_segment(segment_idx)\n",
    "\n",
    "        # Get the sequence\n",
    "        sequence = self.current_segment_data[local_idx]\n",
    "\n",
    "        # Pad or truncate\n",
    "        if len(sequence) < self.max_length:\n",
    "            padding_length = self.max_length - len(sequence)\n",
    "            input_ids = sequence + [self.pad_token_id] * padding_length\n",
    "            attention_mask = [1] * len(sequence) + [0] * padding_length\n",
    "        else:\n",
    "            input_ids = sequence[:self.max_length]\n",
    "            attention_mask = [1] * self.max_length\n",
    "\n",
    "        labels = input_ids.copy()\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(labels, dtype=torch.long)\n",
    "        }"
   ],
   "metadata": {
    "id": "Xeg2lKqwhchC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# 5. MAIN PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "def main(save_to_drive: bool = True):\n",
    "    \"\"\"\n",
    "    Complete preprocessing pipeline\n",
    "\n",
    "    Args:\n",
    "        save_to_drive: If True, saves all outputs to Google Drive (recommended)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"FOUNDATION MODEL DATA PREPROCESSING PIPELINE\")\n",
    "    if save_to_drive:\n",
    "        print(\"(AUTO-SAVE TO GOOGLE DRIVE)\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "    # Mount Google Drive if needed\n",
    "    if save_to_drive:\n",
    "        from google.colab import drive\n",
    "        print(\"Mounting Google Drive...\")\n",
    "        drive.mount('/content/drive')\n",
    "\n",
    "        drive_base = '/content/drive/MyDrive/ML_Assignment_Data'\n",
    "        os.makedirs(drive_base, exist_ok=True)\n",
    "        print(f\"âœ… Save location: {drive_base}\\n\")\n",
    "\n",
    "    # Step 1: Data Collection\n",
    "    print(\"STEP 1: Data Collection\")\n",
    "    print(\"-\" * 60)\n",
    "    collector = DataCollector(output_dir=\"./raw_data\")\n",
    "\n",
    "    # Collect from multiple sources for diversity\n",
    "    wiki_texts = collector.collect_wikipedia(num_samples=200000)\n",
    "    web_texts = collector.collect_openwebtext(num_samples=200000)\n",
    "\n",
    "    all_texts = wiki_texts + web_texts\n",
    "    collector.get_dataset_stats()\n",
    "\n",
    "    # Step 2: Cleaning and Preprocessing\n",
    "    print(\"\\nSTEP 2: Text Cleaning and Preprocessing\")\n",
    "    print(\"-\" * 60)\n",
    "    cleaner = TextCleaner(min_words=50)\n",
    "    cleaned_texts = cleaner.process_documents(all_texts)\n",
    "\n",
    "    # Clear memory\n",
    "    del wiki_texts, web_texts, all_texts\n",
    "    gc.collect()\n",
    "\n",
    "    # Step 3: Tokenization (MEMORY-SAFE SEGMENTED VERSION)\n",
    "    print(\"\\nSTEP 3: Tokenization\")\n",
    "    print(\"-\" * 60)\n",
    "    tokenizer = TextTokenizer(model_name=\"gpt2\", max_length=512)\n",
    "\n",
    "    # Set output directory\n",
    "    if save_to_drive:\n",
    "        segment_output = os.path.join(drive_base, 'tokenization_segments')\n",
    "    else:\n",
    "        segment_output = './tokenization_segments'\n",
    "\n",
    "    # Process in segments (prevents memory crash)\n",
    "    segment_dir = tokenizer.process_documents_segments(\n",
    "        documents=cleaned_texts,\n",
    "        segment_size=50000,\n",
    "        output_dir=segment_output\n",
    "    )\n",
    "\n",
    "    # Get metadata about segments\n",
    "    metadata_info = tokenizer.load_segments_metadata(segment_dir)\n",
    "\n",
    "    # Clear memory\n",
    "    del cleaned_texts\n",
    "    gc.collect()\n",
    "\n",
    "    # Step 4: Create Dataset and DataLoader\n",
    "    print(\"\\nSTEP 4: Creating Dataset and DataLoader\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Use SegmentedDataset (memory-efficient)\n",
    "    dataset = SegmentedPretrainingDataset(\n",
    "        segment_dir=segment_dir,\n",
    "        max_length=512,\n",
    "        pad_token_id=tokenizer.tokenizer.pad_token_id\n",
    "    )\n",
    "\n",
    "    # Create DataLoader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=8,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=False\n",
    "    )\n",
    "\n",
    "    print(f\"âœ… Dataset created: {len(dataset):,} sequences\")\n",
    "    print(f\"âœ… DataLoader created\")\n",
    "\n",
    "    # Step 5: Save sample batches\n",
    "    print(\"\\nSTEP 5: Saving Sample Batches\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    # Set save directory\n",
    "    if save_to_drive:\n",
    "        processed_dir = os.path.join(drive_base, 'processed_data')\n",
    "    else:\n",
    "        processed_dir = './processed_data'\n",
    "\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "    sample_batches = []\n",
    "    print(\"Generating sample batches...\")\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        if i >= 5:  # Save first 5 batches\n",
    "            break\n",
    "        sample_batches.append(batch)\n",
    "        print(f\"  Batch {i+1} shape: {batch['input_ids'].shape}\")\n",
    "\n",
    "    batch_path = os.path.join(processed_dir, 'sample_batches.pt')\n",
    "    torch.save(sample_batches, batch_path)\n",
    "    print(f\"âœ… Saved to: {batch_path}\")\n",
    "\n",
    "    # Save metadata\n",
    "    print(\"\\nSTEP 6: Saving Metadata\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    metadata = {\n",
    "        'total_sequences': len(dataset),\n",
    "        'max_sequence_length': 512,\n",
    "        'vocab_size': tokenizer.tokenizer.vocab_size,\n",
    "        'tokenizer_type': 'GPT2-BPE',\n",
    "        'num_segments': metadata_info['num_segments'],\n",
    "        'segment_dir': segment_dir,\n",
    "        'saved_to_drive': save_to_drive\n",
    "    }\n",
    "\n",
    "    metadata_path = os.path.join(processed_dir, 'metadata.json')\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "\n",
    "    print(f\"âœ… Saved to: {metadata_path}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âœ… PIPELINE COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    if save_to_drive:\n",
    "        print(f\"\\nðŸ’¾ All files saved to Google Drive:\")\n",
    "        print(f\"   {drive_base}\")\n",
    "        print(f\"\\nâœ… Files will persist after restart!\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  Files saved to temporary storage\")\n",
    "        print(f\"   Will be deleted after restart!\")\n",
    "\n",
    "    print(\"\\nOutputs:\")\n",
    "    print(f\"  - Raw data: ./raw_data/\")\n",
    "    print(f\"  - Tokenization segments: {segment_dir}/\")\n",
    "    print(f\"  - Sample batches: {batch_path}\")\n",
    "    print(f\"  - Metadata: {metadata_path}\")\n",
    "    print(f\"\\nDataset Info:\")\n",
    "    print(f\"  - Total sequences: {len(dataset):,}\")\n",
    "    print(f\"  - Number of segments: {metadata_info['num_segments']}\")\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "    return dataset, dataloader\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    dataset, dataloader = main(save_to_drive=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "110348d73ecf4bc8aca02e8e9ad6aeb7",
      "bcdfb1c950284d36b0ec5ca175fd0a79",
      "ad4e0005a7b440f9bee549f5150fde47",
      "2ff517d054374892a9fcb5b0601ca681",
      "ac8e6c7fab0641b9b920bfe641084c8d",
      "d22ce8b2243644438da2c9fda1e50d5e",
      "f1dc62a5f3aa401ea964b1d90f5f1c57",
      "0ef5912f7bdf4a8b977628bef00a1e8f",
      "029ac290ad274342b5115ec21dcdc497",
      "66072f43151f4d8f8dd8cad4303486af",
      "b4301d5afa7e44b4b9e73965e15e995a",
      "74bdfedb725140cfbdd1cbafb31423a8",
      "32ea5e067d1241c39a996c1a93ee1122",
      "904e6d35554843e4a8224a8c81d50f7c",
      "9ec4bc1996a548afa3f86a433d7c7b85",
      "bf15babd6312458996b6e58162cece77",
      "52bb2ee52dc843f685b2b5ab875a979f",
      "085f47505bc04857a0ac2da15921dc9e",
      "3e6616e7eecf42e6a7c5707fb44212e2",
      "42a1ac49078c4129b6aeef4dedf1b9c7",
      "5d7ccf9e648443ce958b11b2e824ebd7",
      "26f6966e1e34489ebadff91fe32bc68e",
      "49355c10a05447e6a6f1484b7624ccb1",
      "1dfa62ed48b5428791441427545d3634",
      "873012c1265a483096c2972e7d810408",
      "d52182e8e9964fcdbba53456b7436bb0",
      "b6d2c94dcd294dac9ce6e7b3a868fee7",
      "249ee4f556174708970279010aca3221",
      "18a781d000854985b7c8afcb684427f7",
      "e9f1c6ed2f71428395377ffd6b60e251",
      "903505210ee44634bed282c23a8d1781",
      "2f900b95c86a48828b45ece489471f6f",
      "2e614251b8fe4838819eb1d6da7b4b54"
     ]
    },
    "id": "BDcefLHUAE_V",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1768634688497,
     "user_tz": 480,
     "elapsed": 6352978,
     "user": {
      "displayName": "Tony Tang",
      "userId": "12580708735148029113"
     }
    },
    "outputId": "196a42c8-5068-4026-a4ce-740c0580bb2a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============================================================\n",
      "FOUNDATION MODEL DATA PREPROCESSING PIPELINE\n",
      "(AUTO-SAVE TO GOOGLE DRIVE)\n",
      "============================================================\n",
      "\n",
      "Mounting Google Drive...\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "âœ… Save location: /content/drive/MyDrive/ML_Assignment_Data\n",
      "\n",
      "STEP 1: Data Collection\n",
      "------------------------------------------------------------\n",
      "Collecting Wikipedia data...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "110348d73ecf4bc8aca02e8e9ad6aeb7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Wikipedia: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200000/200000 [01:21<00:00, 2464.22it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting OpenWebText data...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/80 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74bdfedb725140cfbdd1cbafb31423a8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Resolving data files:   0%|          | 0/80 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49355c10a05447e6a6f1484b7624ccb1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "OpenWebText: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200000/200000 [01:01<00:00, 3251.76it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "============================================================\n",
      "DATASET STATISTICS\n",
      "============================================================\n",
      "wikipedia.txt: 835.40 MB (0.8158 GB)\n",
      "openwebtext.txt: 951.99 MB (0.9297 GB)\n",
      "\n",
      "Total Size: 1.7455 GB\n",
      "============================================================\n",
      "\n",
      "\n",
      "STEP 2: Text Cleaning and Preprocessing\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Cleaning documents: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400000/400000 [08:57<00:00, 743.84it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "============================================================\n",
      "CLEANING STATISTICS\n",
      "============================================================\n",
      "Total documents: 400000\n",
      "Duplicates removed: 70\n",
      "Low quality removed: 10695\n",
      "Documents kept: 389235\n",
      "Retention rate: 97.31%\n",
      "============================================================\n",
      "\n",
      "\n",
      "STEP 3: Tokenization\n",
      "------------------------------------------------------------\n",
      "\n",
      "Tokenizer Info:\n",
      "  Model: gpt2\n",
      "  Vocab size: 50257\n",
      "  Max length: 512\n",
      "  Fast tokenizer: True\n",
      "  Tokenization type: BPE (Byte-Pair Encoding)\n",
      "\n",
      "\n",
      "============================================================\n",
      "MEMORY-SAFE SEGMENTED TOKENIZATION\n",
      "============================================================\n",
      "  Total documents: 389,235\n",
      "  Segment size: 50,000\n",
      "  Number of segments: 8\n",
      "  Output directory: /content/drive/MyDrive/ML_Assignment_Data/tokenization_segments\n",
      "============================================================\n",
      "\n",
      "âœ“ Segment 0/7 already exists, loading...\n",
      "âœ“ Segment 1/7 already exists, loading...\n",
      "âœ“ Segment 2/7 already exists, loading...\n",
      "âœ“ Segment 3/7 already exists, loading...\n",
      "âœ“ Segment 4/7 already exists, loading...\n",
      "âœ“ Segment 5/7 already exists, loading...\n",
      "âœ“ Segment 6/7 already exists, loading...\n",
      "âœ“ Segment 7/7 already exists, loading...\n",
      "\n",
      "============================================================\n",
      "âœ… ALL SEGMENTS COMPLETE\n",
      "============================================================\n",
      "  Total sequences: 930,229\n",
      "  Segments saved in: /content/drive/MyDrive/ML_Assignment_Data/tokenization_segments\n",
      "============================================================\n",
      "\n",
      "Loading segment metadata...\n",
      "\n",
      "STEP 4: Creating Dataset and DataLoader\n",
      "------------------------------------------------------------\n",
      "Counting sequences in segments...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loading metadata: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [11:16<00:00, 84.53s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "âœ… Total sequences: 930,229\n",
      "\n",
      "âœ… Dataset created: 930,229 sequences\n",
      "âœ… DataLoader created\n",
      "\n",
      "STEP 5: Saving Sample Batches\n",
      "------------------------------------------------------------\n",
      "Generating sample batches...\n",
      "  Batch 1 shape: torch.Size([8, 512])\n",
      "  Batch 2 shape: torch.Size([8, 512])\n",
      "  Batch 3 shape: torch.Size([8, 512])\n",
      "  Batch 4 shape: torch.Size([8, 512])\n",
      "  Batch 5 shape: torch.Size([8, 512])\n",
      "âœ… Saved to: /content/drive/MyDrive/ML_Assignment_Data/processed_data/sample_batches.pt\n",
      "\n",
      "STEP 6: Saving Metadata\n",
      "------------------------------------------------------------\n",
      "âœ… Saved to: /content/drive/MyDrive/ML_Assignment_Data/processed_data/metadata.json\n",
      "\n",
      "============================================================\n",
      "âœ… PIPELINE COMPLETE!\n",
      "============================================================\n",
      "\n",
      "ðŸ’¾ All files saved to Google Drive:\n",
      "   /content/drive/MyDrive/ML_Assignment_Data\n",
      "\n",
      "âœ… Files will persist after restart!\n",
      "\n",
      "Outputs:\n",
      "  - Raw data: ./raw_data/\n",
      "  - Tokenization segments: /content/drive/MyDrive/ML_Assignment_Data/tokenization_segments/\n",
      "  - Sample batches: /content/drive/MyDrive/ML_Assignment_Data/processed_data/sample_batches.pt\n",
      "  - Metadata: /content/drive/MyDrive/ML_Assignment_Data/processed_data/metadata.json\n",
      "\n",
      "Dataset Info:\n",
      "  - Total sequences: 930,229\n",
      "  - Number of segments: 8\n",
      "\n",
      "============================================================\n"
     ]
    }
   ]
  }
 ]
}